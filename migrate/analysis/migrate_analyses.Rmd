---
title: "Dongsha Migrate Analysis"
output: html_notebook
---

Here is code that I used to set up migrate analyses on datasets from Dongsha atoll. These data are from samples that were collected by Rob Toonen, Michelle Gaither, Vanson Liu and Hawis Maduppa. The data themselves were largely generated by students in the BIO 444 class, and these students also set up the initial migrate runs for their class project. To do so they downloaded data from their species from GeOMe and picked 4-5 closest populations and set up several hypotheses about the best metapopulation model. I am now just taking those runs and re-running them twice more as migrate does not always converge well on a marginal likelihood for a model.



# Setting up the runs

## Renaming parmfiles
At first I was just going to set up a screen for each run and run them all manually, but decided to write a script to rename the parmfiles uniformly. It finds files with the word "Parmfile" in them and then renames them to "parmfile"
```{bash parmfile_namer.sh}
#!
for d in */
        do
          cd $d
          echo $d
            for e in */
            do
            echo $e
            cd $e
                for f in $(find ./ -maxdepth 1 -type f -exec grep -l 'Parmfile' {} \;)
                 do 
                         echo mv $f parmfile
                         mv $f parmfile
                 done
             cd ..
             done
          cd ..
        done  
 

```

I then deleted all the PDF outfiles from the directories to mark each directory as new (I had copied directories with finished analyses)
```{bash}
 find . -type f -iname "*.pdf" -delete
```

## Script to set up runs
I used the following script to automagically set up a screen and run migrate in each sub-directory
```{bash screen_migrate.sh}
#!
#for s in */
#do
#       cd $s

        for m in */
        do
                cd $m
                echo $m
                screen -d -m migrate-n
                cd ..
        done
#       cd ..
#done
```

So now "Round 2" of these runs is off and running. I'll wait a week to check in and start round 3.

8/23/18

Finished Round 3

## Renaming Outfiles

Rename outfiles like so
```{bash}
#!
for d in */
        do
          cd $d
          echo $d
                for f in $(find ./ -maxdepth 1 -type f -exec grep -l 'Options in use' {} \;)
                 do 
                         echo mv $f outfile.txt
                 done
          cd ..
        done  
  
#And wrap that up in a loop

M053-303-26932:dongsha1 cran5048$ for e in */
> do
> cd $e
> echo $e
> bash ../../outfile_renamer.sh
> cd ..
> done

```

# Processing output

## Function for bayes factor calculations
```{r bfcalcs}
# a function for calculating model selection statistics
bfcalcs<-function(df,ml="bezier.corrected"){
  df$thermodynamic<-as.numeric(df$thermodynamic)
  df$bezier.corrected<-as.numeric(df$bezier.corrected)
  df$harmonic<-as.numeric(df$harmonic)
    mlcol<-df[,ml] 
	bmvalue<-mlcol[which.max(mlcol)]
	lbf<-2*(mlcol-bmvalue)
	choice<-rank(-mlcol)
	modelprob<-exp(lbf/2)/sum(exp(lbf/2))
	dfall<-cbind(df,lbf,choice,modelprob)
	return(dfall)
}	
```


## Harvesting Likelihoods

```{r harvest_likelihoods}
wd<-"~/Datasets/dongsha_migrate/"
setwd(wd)
m<-c("panmixia","n_island","stepping_stone")
#m<-c("panmixia","n_island","dongsha_sink","dongsha_source","stepping_stone")



likelists<-list()
for(r in 1:3){
  wd1<-paste(wd,"dongsha",r,sep="")
  setwd(wd1)
  # start here if you just want to do one list
  likelist<-list() #initialize an empty list
  for(f in list.files()){
    wd2<-file.path(wd1,f)
    marglike<-data.frame(model=character(0),thermodynamic=numeric(0),bezier.corrected=numeric(0),harmonic.mean=numeric(0),stringsAsFactors=F) #initialize a data frame to take the values
    l=1 #initialize l
    for(i in m){ #i<-"stepping_stone"
      wd3<-file.path(wd2,i)
      print(wd3)
      if(!file.exists(wd3)){next}
      setwd(wd3)
      outfile<-scan(file="outfile.txt",what="character",sep="\n") #scan in the outfile, separating at each newline
      
      #get the result from thermodynamic integration
      thermoline<-grep("(1a)",outfile,value=T) #find the line with the thermodynamic likelihood on it
      if(length(thermoline)==0){next}
      thermoline<-strsplit(thermoline,split="=",fixed=T) #split it up
      thermo<-as.numeric(substr(thermoline[[1]][2],start=1,stop=12)) #grab the thermodynamic likelihood
      bezistart<-grep("\\(",strsplit(thermoline[[1]][2],split="")[[1]])+1
      bezier<-as.numeric(substr(thermoline[[1]][2],start=bezistart,stop=bezistart+11)) #and the bezier-corrected value
      #get the harmonic mean
      harmoline<-grep("\\(2\\) H",outfile,value=T) #find the line with harmonic mean likelihood on it
      harmoline<-strsplit(harmoline,split="=",fixed=T) #grab the harmonic mean
      harmo<-as.numeric(substr(harmoline[[1]][2],start=1,stop=12))
      marglike[l,]<-c(i,thermo,bezier,harmo) #add this as a row to the data frame
      l=l+1
    }
    

    
    likelist[[f]]<-marglike #add the dataframe to the list
  }
  
# stop here if you just want one round  
  likelists[[r]]<-likelist
}
setwd(wd)
```

## Model Selection
On each round, and then bind them into a list
```{r model_selection}
modeltable1<-lapply(likelists[[1]],bfcalcs)
modeltable2<-lapply(likelists[[2]],bfcalcs)
modeltable3<-lapply(likelists[[3]],bfcalcs)
modeltables<-list("round1"=modeltable1,"round2"=modeltable2,"round3"=modeltable3)

head(modeltables[[1]],1)
```

## Plot marginal likelihood results from each of 3 runs
```{r}
library(ggplot2)
setwd(wd)
speciesnames<-read.csv("~/github/dongsha/species_names.csv")

pdf(file = "thermodynamic_marginal_likelihoods_final.pdf",width=8.5,height=3)
means<-list()
#plots<-list()
for(dataset in names(modeltables[[1]])){
  likes<-rbind(cbind(modeltables[[1]][[dataset]],rep=1), cbind(modeltables[[2]][[dataset]],rep=2), cbind(modeltables[[3]][[dataset]], rep=3))
  likes$model<-factor(likes$model, m)
  likes<-likes[!(is.na(likes$model)),]
  
speciesname<-speciesnames$Species[which(speciesnames$Working==dataset)]
  
  #likes<-likes[which(likes$bezier.corrected > max(likes$bezier.corrected)-100),]
  y.mean<-as.vector(by(likes$bezier.corrected,likes$model,mean))
  y.sd<-as.vector(by(likes$bezier.corrected,likes$model,sd))
  y.min<-y.mean-((y.sd/sqrt(3))*4.303)
  y.max<-y.mean+((y.sd/sqrt(3))*4.303)

    
  likes.mean<-data.frame(model=factor(m,m),y.mean,y.min,y.max,y.sd)
  means[[dataset]]<-likes.mean
  
  #l<-ggplot(data=likes, aes(x=model,y=bezier.corrected,colour=factor(rep), 
   #                                 shape=factor(rep), size=20 ))
  l<-ggplot(data=likes, aes(x=model,y=bezier.corrected))
  
  l<-l+geom_point(colour="blue", size=3)+
    geom_pointrange(data=likes.mean,y=y.mean,ymin=y.min,ymax=y.max, size=0.5)+
    scale_x_discrete(drop=FALSE)+
    theme(axis.text.y = element_text(size=16),legend.position="none",axis.title.x=element_text(size=16),axis.title.y=element_blank(),plot.title=element_text(size=20))+ggtitle(speciesname)+ylab("Marginal Log-Likelihood")+
    coord_fixed(0.1)+ coord_flip()
  print(l)
#  plots<-c(plots,l)
}
dev.off()


```

## Take the mean marginal likelihoods over three runs and calculate model selection tables.
```{r}
library(perm)

meanlikes<-list()
permtests<-data.frame(matrix(ncol = 8, nrow = 0))
colnames(permtests)<-c(m,"k-means p-value","Best Mean","Second Best Mean","p-value Best Mean > Second Mean", "Ln Bayes Factor")

for(dataset in names(modeltables[[1]])){
  print(dataset)
  likes<-rbind(cbind(modeltables[[1]][[dataset]],rep=1), cbind(modeltables[[2]][[dataset]],rep=2), cbind(modeltables[[3]][[dataset]], rep=3))
  likes$model<-factor(likes$model, m)
  likes<-likes[!(is.na(likes$model)),]
  likes$model<-factor(likes$model, m)
  y.mean<-as.vector(by(likes$bezier.corrected,likes$model,mean)) #take the means for each model
  kmeans.p<-permKS(x = likes$bezier.corrected, g = likes$model, 
                   method="exact.mc")$p.value #k-means non-parametric test to compare all means
  bestmean<-m[order(y.mean,decreasing=T)[1]] # get the highest mean
  secondmean<-m[order(y.mean,decreasing=T)[2]] #get the second best mean
  ttest<-permTS(x=likes$bezier.corrected[which(likes$model==bestmean)],
                y=likes$bezier.corrected[which(likes$model==secondmean)], 
                alternative="greater", method="exact.ce")
  
  
  values<-rbind(y.mean)
  bmvalue<-y.mean[which.max(y.mean)]
	lbf <- 2*(y.mean-bmvalue)
  values<-cbind(values,kmeans.p,bestmean,secondmean,ttest$p.value,sort(lbf)[2])
  
  permtests[dataset,]<-values


	modelrank<-rank(-y.mean)
	modelprob<-exp(lbf/2)/sum(exp(lbf/2),na.rm=T)
	dfall<-cbind("Mean Bezier Corrected ML"=as.numeric(y.mean),"LBF"=as.numeric(lbf),"Rank"=as.numeric(modelrank),"Model_Probability"=as.numeric(modelprob))
	row.names(dfall)<-m
	dfall<-as.data.frame(dfall)
	meanlikes[[dataset]]<-dfall
  
}
```

## Calculate the best models table and save it
```{r}
getmodels2<-function(dfr){
  model1<-row.names(dfr)[which(dfr$Rank==1)]
  model2<-row.names(dfr)[which(dfr$Rank==2)]
  modelprob1<-dfr$Model_Probability[which(dfr$Rank==1)]
  modelprob2<-dfr$Model_Probability[which(dfr$Rank==2)]
  lnBF <- dfr$LBF[which(dfr$Rank ==2)]
  print(model1)
  print(model2)
  print(modelprob1)
  c(model1,modelprob1,model2,modelprob2,lnBF)
}

bestmodeltable<-lapply(meanlikes,getmodels2)
bestmodeltable<-t(as.data.frame(bestmodeltable))
colnames(bestmodeltable)<-c("bestmodel","bestmodelprob","secondbestmodel","secondbestmodelprob","lnBF")
bestmodeltable<-cbind(bestmodeltable,permtests[,c(4,8)])


write.csv(bestmodeltable,file="Final_BestModeltable_Using_Means_of_3reps.csv")
write.csv(permtests,file="Permutation_ttest_results.csv")
save(meanlikes,file="Final_Modeltable_Using_Means_of_3reps.R")
```


## Plot Model Probability

```{r model_probability}

#read in the t-test results
#tt<-read.table(file="~/Dropbox/Crandall_tobo/scripts/Final_BestModeltable_Using_Means_of_3reps.csv",header=T,sep=",")

means<-data.frame(dataset=character(),species=character(),common=character(),
                  models=character(),modelprob=numeric())
#names<-read.csv("Species_names.csv", stringsAsFactors = F)

for(dataset in names(modeltables[[1]])){
  #make a long dataset of model probabilities from each dataset
  species<-speciesnames[which(speciesnames$Working==dataset),2] #lookup the species name

  likes<-rbind(cbind(modeltables[[1]][[dataset]],rep=1), cbind(modeltables[[2]][[dataset]],rep=2), cbind(modeltables[[3]][[dataset]], rep=3))
  likes$model<-factor(likes$model, m)
  likes<-likes[!(is.na(likes$model)),]
  #take the mean model probability
  y.mean<-as.vector(by(likes$modelprob,likes$model,mean))
  #put this back in a data frame with model
  likes.mean<-data.frame(dataset=dataset,species=species,model=factor(m,m),modelprob=y.mean)
  means<-rbind(means,likes.mean)
}

#CODE FOR SORTING SPECIES
#take the value for stepping stone from each model and sort on it
#species<-unique(as.character(means$species)) #make a character vector of all species

#set mean probs for stepping stone that are less than 0.01 to 0 so I can also sort on panmixia
#means[means$model=="stepping.stone" & means$modelprob<0.01,"modelprob"]<-0
#sort it by value of stepping.stone
#species2<-species[order(-tt$ttest_pvalue, #means[means$model=="stepping.stone","modelprob"], #means[means$model=="stepping.stone.1param","modelprob"],
#means[means$model=="hi_lo","modelprob"],
#means[means$model=="empirical","modelprob"],
#means[means$model=="n.island","modelprob"],
#                        decreasing=T)] 
#
#means$model<-factor(means$model,levels=m,labels=c("k <= 14, Stepping-Stone, ~40 parameter","k <= 14, Stepping-Stone, 2 parameter","k = 3, 2 Currents, 7 parameter","k = 2, 1 Current, 4 parameter", "k = 2, High/Low Islands, 4 parameter","k = ? Empirical Structure, ? parameter","k <= 14, n-Island, 2 parameter","k=1, Panmixia, 1 parameter"))


#means$species<-factor(means$species,levels=species2)
means$model<-factor(means$model,levels=m,labels=c("Panmixia","N-Island","Stepping-Stone"))

library(ggplot2)
library(RColorBrewer)

my.cols<-rev(brewer.pal(5,"RdYlBu"))
my.cols<-my.cols[c(1,2,5)]
my.cols[1]<-"#7f7f7f"



mprobs<-ggplot(data=means,mapping=aes(x=species,y=modelprob,fill=model)) + 
  geom_bar(stat="identity") + scale_fill_manual(values=my.cols, guide = guide_legend(title = "Migrate Models")) + 
  theme(axis.text.x=element_text(angle=90, hjust=1,vjust=0.5, color=c(rep("grey25",26),rep("grey70",15))), legend.text = element_text(size = 14), legend.title = element_text(size = 20), axis.text.y= element_text(size = 14), axis.title.y=element_text(size=14)) +
  scale_y_continuous(name="Model Probability") + scale_x_discrete(name="Species")

mprobs

ggsave(filename = "dongsha_bars_final_landscape.pdf", width = 8, height=6,units = "in")
```


## Re-running models

1/8/2021

Argg! As I went to write the paper, I found that some of the students had mis-specified some of their migrate models. I am now re-running these at Pennsylvania State University. Only going to re-run models with directories labeled with "_r"

```{unix migrate_batch.sh}
#!
for s in $(find ./ -maxdepth 1 -type d -name "*_r*")
do
      cd $s

        for m in $(find ./ -maxdepth 1 -type d -name "*_r*")
        do
                cd $m
                echo $m
                screen -d -m migrate-n
                cd ..
        done
    cd ..
done

```
}

# Migration parameters

```{r setup_parameters}
# Load packages
library(coda)
library(ggmcmc)
library(gridExtra)
library(reshape2)
library(modeest)

#a function for creating Nm vectors out of m and Theta vectors.
migrants.per.gen<-function(x){
  #x<-x[[1]]
  m<-names(x)[which(grepl("M_",names(x)))] #names of m columns
  #theta<-names(x)[which(grepl("Theta_",names(x)))] #names of theta columns
  for(n in m){
    t<-paste("Theta",strsplit(n,split="_")[[1]][3],sep="_")
    x[,paste("Nm",strsplit(n,split="_")[[1]][2],strsplit(n,split="_")[[1]][3],sep="_")]<-  	x[,which(names(x)==n)]*x[,which(names(x)==t)] #this hairy little statement makes a new column named "Nm_X_Y" and then fills it by multiplying the M_X_Y column by the Theta_Y column	
  }
  return(x)
}

in.v.out<-function(x,parameters){
  #x<-x[[1]]
  outies <- paste0("M_",parameters[seq(1,length(parameters),by=2)])
  innies <- paste0("M_",parameters[seq(2,length(parameters),by=2)])
  names(x)[names(x) %in% outies] <- paste0(names(x)[names(x) %in% outies],"_Out")
  names(x)[names(x) %in% innies] <- paste0(names(x)[names(x) %in% innies],"_Into")
  return(x)
}

mode <- function(x){
dens = density(x)
mo = dens$x[which.max(dens$y)]
return(mo)
}


```

# Logistic Regression of PLD on Model

Following along [here](https://stats.idre.ucla.edu/r/dae/logit-regression/)

```{r}
library(raster)
library(tidyverse)



species <-read.csv("~/github/dongsha/Species_names.csv")
dvertices <- read.csv("~/github/dongsha/migrate/dongsha_vertices.csv")
#species$Migrate_Model <- factor(species$Migrate_Model, levels = c("Stepping-Stone", "Panmixia"), ordered=F)
distances <- tibble(dongsha = dvertices[1,c(6,5)], sp = species$Working)
closest <- c("Philippines","Palau","Bunaken","Philippines","Taiwan","Okinawa",
             "Guam","Philippines","Taiwan")
farthest <- c("Okinoerabu","Christmas Island","Krakatau","Great Barrier Reef","Okinawa","Kwajalein","Fiji","Okinawa","Okinawa")
distances <- distances %>% bind_cols(closestPop=closest, farthestPop = farthest) %>%
              left_join(dvertices[,c(2,6,5)], by= c("closestPop" = "island"))  %>%
              left_join(dvertices[,c(2,6,5)], by= c("farthestPop" = "island"))

species$closestDistance <- pointDistance(distances$dongsha, 
                                           distances[,c(5,6)], lonlat = T)/1000
species$farthestDistance <- pointDistance(distances$dongsha, 
                                           distances[,c(7,8)], lonlat = T)/1000



#species$Migrate_Model<-relevel(species$Migrate_Model, ref="Stepping-Stone")
#species$Max_PLD <- log(species$Max_PLD)
species$Migrate_Model <- factor(species$Migrate_Model, 
                                levels = c("Panmixia","Stepping-Stone"))

#pld_model_mm <- multinom(Migrate_Model ~ Max_PLD, data = species)

pld_model_l <- glm(Migrate_Model ~ Max_PLD, 
                   data = species, family = "binomial")

pld_model_l2 <- glm(Migrate_Model ~ Max_PLD * farthestDistance * closestDistance, 
                    data = species, family = "binomial")

step_l2 <- stepAIC(pld_model_l2, directions = "backward")

pld_model_l3 <- glm(Migrate_Model ~ Max_PLD * closestDistance, 
                    data = species, family = "binomial")

step_l3 <- stepAIC(pld_model_l3)

with(pld_model_l, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))

exp(cbind(OR = coef(pld_model_l), confint(pld_model_l)))

predict.df <- tibble(Max_PLD = seq(1,180), closestDistance = 238, farthestDistance = 500)

prob_ss<-data.frame(Max_PLD,predict(pld_model_l, predict.df, type = "link", se = TRUE))

species<-species %>% mutate(Prob = as.numeric(Migrate_Model)-1)

prob_ss <- prob_ss %>% mutate(Prob = plogis(fit), LL = plogis(fit - (1.96 * se.fit)), 
                              UL = plogis(fit + (1.96 * se.fit)))

ggplot(prob_ss, aes(x = Max_PLD, y = Prob)) + 
  geom_ribbon(aes(ymin = LL,ymax = UL), fill = "blue", alpha = 0.2) +
  geom_line() + 
  geom_point(data = species, mapping = aes(x = Max_PLD, y = Prob, 
                                           color = Migrate_Model)) + 
  geom_text(data = species, mapping = aes(x = Max_PLD, y = Prob, label = Species,
                                          vjust = 2), size = 2, angle = 45) +
  scale_color_discrete(type=c("white","black")) + 
  ylab("Probability of Dongsha Stepping-Stone") + 
  xlab("Maximum Pelagic Larval Duration") +
  xlim(20,70) + theme(legend.position = "none")

ggsave(filename = "./migrate/dongsha_logistic_model.pdf", width = 8, height=6,units = "in")

```

```{r}
wd <- "/Users/eric/Datasets/dongsha_migrate"
finaloutput <- "/Users/eric/github/dongsha/migrate/analysis"

names<-read.csv("~/github/dongsha/Species_names.csv", stringsAsFactors = F)
model <- "stepping_stone"
ssNm <- tibble()
ssM <- tibble()
ssT <- tibble()
directional <- tibble()

for(sp in c("c_striatus","c_vroliki","c_auriga","a_japonicus")){
#sp <- "a_japonicus"

  splevels_list <- list(a_japonicus = c("1_2","2_1","1_3",
                                   "3_1","1_4","4_1"),
                   c_vroliki = c("1_2","2_1"),
                   c_striatus = c("1_2","2_1"),
                   c_auriga = c("2_3","3_2"))
  
  splevels <- splevels_list[[sp]]
  spname <- names$Species[which(names$Working == sp)]
  
  print(paste("Starting", spname))
  
  data.list<-list() #initialize an empty data list
  allstatstable<-list()
  
    for(r in 1:3){  #loop through the 3 replicate rounds
        wd1<-file.path(wd,paste("dongsha",r,sep=""),sp,model)
        setwd(wd1)  #move into that species' and model directory
        
        print(paste("loading and processing bayesallfile for round", r))
        data<-read.table("bayesallfile", header=T) #this may take a minute or two
      
        # Split the whole list into the individual replicates, so that you will
        # have a list of data frames
        data.list.1<-split(data,data$Replicate)
        
        # Burnin already removed for this project
        
        # calculate Nm for each row
        data.list.2<-lapply(data.list.1,migrants.per.gen)
        
        # rename M parameters
        data.list.2 <- lapply(data.list.2, in.v.out, parameters=splevels)
        
        # cat it onto the main list
        data.list<-c(data.list,data.list.2)
    }
    
    #convert each dataframe to an mcmc object and then convert the whole thing to an mcmc list
      #data.list.mcmc<-mcmc.list(lapply(data.list,mcmc))
      #condense everything into a single mcmc replicate for the purposes of HPDinterval
      #data.list.allinone<-mcmc(data=do.call("rbind",data.list)) 
      
      #calculate statistics
      #print("calculating statistics")
      #summ<-summary(data.list.mcmc)
      #ess<-effectiveSize(data.list.mcmc)
      #gelman<-gelman.diag(data.list.mcmc,multivariate=F)
      #HPD<-HPDinterval(data.list.allinone)
      
      #cat the stats, man
      #allstats<-cbind(summ$statistics[,1:2],HPD,ess,gelman$psrf)
      #allstatstable[[f]]<-allstats
      
      #write the stats into the directory for future reference
      #write.csv(allstats,file.path(finaloutput,paste(sp,model,"codastats.csv")))
      
      
      
      #print("plotting MCMC")
      
      #data.list.plot<-lapply(data.list,subset,select=c(which(grepl("Theta_",names(data.list[[1]])) |
      #                                                         grepl("M_",names(data.list[[1]])) |
      #                                                        grepl("Nm_",names(data.list[[1]])) |
      #                                                         grepl("lnPost",names(data.list[[1]])))))
      #
      #log transform them, since they come from an exponential prior
      #data.list.plot<-lapply(data.list.plot,log)
      #data.list.plot<-mcmc.list(lapply(data.list.plot,mcmc))
    
      #data.list.gg<-ggs(data.list.plot,burnin=F,description=paste(f,model,sep="_"))
      #ggmcmc(data.list.gg,plot=c("ggs_traceplot","ggs_density","ggs_Rhat"),
      #       simplify_traceplot=0.25,file=file.path(finaloutput,paste(sp,model,".pdf",sep="")))
      
      
      
      cat("Adding to Nm Violin Plots") 
      #isolate Nm values for violin plots

  
      longNm <- data.list %>% bind_rows() %>% select(contains(paste0("Nm_",splevels), ignore.case = F)) %>%
                melt(measure.vars = paste0("Nm_",splevels), variable.name = "Parameter", value.name = "Nm") %>%
                mutate(Species = spname)
  
      longNm$Parameter <- factor(longNm$Parameter, 
                                   levels =  paste0("Nm_",splevels),
                                   labels = rep(c("Out of Dongsha","Into Dongsha"), 
                                                times = length(splevels)/2), 
                                   ordered = F)
  
      ssNm <- bind_rows(ssNm, longNm)
      
      

    cat("Adding to m/mu Violin Plots") 
 
      longM <- data.list %>% bind_rows() %>% select(contains(paste0("M_",splevels), ignore.case = F)) %>%
                melt(variable.name = "Parameter", value.name = "M") %>%
                mutate(Species = spname)
      
      llevels <- levels(longM$Parameter)
  
      longM$Parameter <- factor(longNm$Parameter, ordered = F)
                                
                                   
  
      ssM <- bind_rows(ssM, longM)
      
    cat("Adding to Theta Violin Plots")
      
      #pick the Dongsha Population
      dongsha <- as.numeric(substr(splevels[1], start = 1, stop = 1))
      longT <- data.list %>% bind_rows() %>% select(contains(paste0("Theta_",dongsha), ignore.case = F)) %>%
                melt(measure.vars = paste0("Theta_",dongsha), variable.name = "Parameter", 
                     value.name = "Theta") %>%
                mutate(Species = spname)
  
      ssT <- bind_rows(ssT, longT)
      
      
      
  cat("Adding to Directional Gene Flow Analysis")
  
    out_v_in <- data.list %>% bind_rows() %>% select(contains("M_", ignore.case = F)) %>%
                    mutate(sum_out = rowSums(across(ends_with("Out")))) %>% 
                    mutate(sum_in = rowSums(across(ends_with("Into")))) %>%
                    mutate(out_over_in = sum_out/sum_in) %>% select(c("sum_out", "sum_in","out_over_in")) %>%
                    mutate(Species = spname)
    
    directional <- bind_rows(directional, out_v_in)
    
     #calculate statistics for directional dataset
      print("calculating directional statistics")
      prob_mode <- out_v_in %>% summarize(ProbSource = (sum(out_over_in < 1) / n()),
                                         Mode_Out_over_In = mlv(out_over_in, method = "hsm"))
      out_v_in.mcmc <- mcmc(out_v_in[,c(1:3)])
      summ<-summary(out_v_in.mcmc)
      ess<-effectiveSize(out_v_in.mcmc)
      HPD<-HPDinterval(out_v_in.mcmc)
      allstats_in_v_out<-cbind(prob_mode,summ$statistics[,1:2],HPD,ess)
    
      write.csv(allstats_in_v_out,file.path(finaloutput,paste(sp,"out_v_in","codastats.csv")))
}
    
      violinNm <- ggplot(ssNm, mapping = aes(x=Species, y=Nm, fill=Parameter)) +
                          geom_violin(draw_quantiles=c(0.025,0.5,0.975))  +
                          scale_y_log10(breaks=c(0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000,10000,100000),
                              labels=c("0.00001","0.0001","0.001","0.01","0.1","1",
                                       "10","100","1,000","10,000","100,000"),
                              limits=c(0.001,100000)) +
                              scale_fill_manual(values=c("grey","white")) +
                              labs(x="Species", y="Effective Female Migrants per Generation")
    
      ggsave(file=file.path(finaloutput,paste("final","_",model,"_Nm_violin.pdf",sep="")),
           plot=violinNm,device="pdf",width=11,height=8.5,units="in")
      
      
      violin_directional <- ggplot(directional, mapping = aes(x=Species, y=out_over_in)) +
                          geom_violin(draw_quantiles=c(0.025,0.5,0.975))  +
                          scale_y_log10(breaks=c(0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000,10000,100000),
                              labels=c("0.00001","0.0001","0.001","0.01","0.1","1",
                                       "10","100","1,000","10,000","100,000"),
                              limits=c(0.001,100000)) +
                              labs(x="Species", y="Gene Flow Out of Dongsha / Into Dongsha")
    
      ggsave(file=file.path(finaloutput,paste("final","_",model,"_directional_violin.pdf",sep="")),
           plot=violin_directional,device="pdf",width=11,height=8.5,units="in")

    

    
      violinm<-ggplot(ssM, (aes(x=Species, y=M, fill=Parameter))) + 
        geom_violin(draw_quantiles=c(0.025,0.5,0.975))  + 
        scale_y_log10(breaks=c(0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000,10000,100000,1000000),
                      labels=c("0.00001","0.0001","0.001","0.01","0.1","1","10","100","1,000","10,000",
                               "100,000","1,000,000"),
                      limits=c(0.0001,1000000)) +
        scale_fill_manual(values=c("grey","white")) +
        labs(x="Species", y="proportion of migrants scaled by mutation rate")
      
      ggsave(file=file.path(finaloutput,paste("final","_",model,"_m_violin.pdf",sep="")),plot=violinm,device="pdf",width=11,height=8.5,units="in")
      

    
    violint<-ggplot(ssT, (aes(x=Species, y=Theta))) + geom_violin(draw_quantiles=c(0.025,0.5,0.975))  + 
      scale_y_log10(breaks=c(0.00001,0.0001,0.001,0.01,0.1,1.0,10),
                    labels=c("0.00001","0.0001","0.001","0.01","0.1","1.0","10.0"),
                    limits=c(0.00001,10)) +
      scale_fill_manual(values=c("grey","white")) +
      labs(x="Species", y="Dongsha Theta")
    
    ggsave(file=file.path(finaloutput,paste("final","_",model,"_theta_violin.pdf",sep="")),plot=violint,device="pdf",width=11,height=8.5,units="in")
    
```
